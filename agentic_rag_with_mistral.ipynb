{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs==2.4.3\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting aiohttp==3.10.8\n",
      "  Using cached aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting aiosignal==1.3.1\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting annotated-types==0.7.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting anyio==4.6.0\n",
      "  Using cached anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Collecting arxiv==2.1.3\n",
      "  Using cached arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.4.1)\n",
      "Collecting async-timeout==4.0.3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting attrs==24.2.0\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting cachetools==5.5.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting certifi==2024.8.30\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting charset-normalizer==3.3.2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting click==8.1.7\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.2.2)\n",
      "Collecting dataclasses-json==0.6.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: debugpy==1.8.6 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.8.6)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (5.1.1)\n",
      "Collecting duckduckgo_search==6.2.13\n",
      "  Using cached duckduckgo_search-6.2.13-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.1.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (2.1.0)\n",
      "Collecting faiss-cpu==1.8.0.post1\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "Collecting feedparser==6.0.11\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Collecting frozenlist==1.4.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.6\n",
      "  Using cached google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "Collecting google-api-core==2.20.0\n",
      "  Using cached google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
      "Collecting google-api-python-client==2.147.0\n",
      "  Using cached google_api_python_client-2.147.0-py2.py3-none-any.whl (12.2 MB)\n",
      "Collecting google-auth==2.35.0\n",
      "  Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Collecting google-auth-httplib2==0.2.0\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-generativeai==0.7.2\n",
      "  Using cached google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Collecting googleapis-common-protos==1.65.0\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Collecting greenlet==3.1.1\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "Collecting grpcio==1.66.2\n",
      "  Using cached grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "Collecting grpcio-status==1.62.3\n",
      "  Using cached grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Collecting h11==0.14.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httpcore==1.0.6\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Collecting httplib2==0.22.0\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting httpx==0.27.2\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Collecting idna==3.10\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.28.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (8.28.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 41)) (0.19.1)\n",
      "Collecting jsonpatch==1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jsonpointer==3.0.0\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 44)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 45)) (5.7.2)\n",
      "Collecting langchain==0.3.1\n",
      "  Using cached langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "Collecting langchain-community==0.3.1\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "Collecting langchain-core==0.3.8\n",
      "  Using cached langchain_core-0.3.8-py3-none-any.whl (400 kB)\n",
      "Collecting langchain-google-genai==2.0.0\n",
      "  Using cached langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
      "Collecting langchain-text-splitters==0.3.0\n",
      "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting langgraph==0.2.34\n",
      "  Using cached langgraph-0.2.34-py3-none-any.whl (107 kB)\n",
      "Collecting langgraph-checkpoint==2.0.0\n",
      "  Using cached langgraph_checkpoint-2.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting langsmith==0.1.130\n",
      "  Using cached langsmith-0.1.130-py3-none-any.whl (294 kB)\n",
      "Collecting marshmallow==3.22.0\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 55)) (0.1.7)\n",
      "Collecting msgpack==1.1.0\n",
      "  Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Collecting multidict==6.1.0\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting mypy-extensions==1.0.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 59)) (1.6.0)\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting orjson==3.10.7\n",
      "  Using cached orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Requirement already satisfied: packaging==24.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 62)) (24.1)\n",
      "Requirement already satisfied: parso==0.8.4 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 64)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 65)) (4.3.6)\n",
      "Collecting primp==0.6.3\n",
      "  Using cached primp-0.6.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 67)) (3.0.48)\n",
      "Collecting proto-plus==1.24.0\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Collecting protobuf==4.25.5\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Requirement already satisfied: psutil==6.0.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 70)) (6.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 71)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 72)) (0.2.3)\n",
      "Collecting pyasn1==0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Collecting pyasn1_modules==0.4.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting pydantic==2.9.2\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Collecting pydantic-settings==2.5.2\n",
      "  Using cached pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Collecting pydantic_core==2.23.4\n",
      "  Using cached pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Requirement already satisfied: Pygments==2.18.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 78)) (2.18.0)\n",
      "Collecting PyMuPDF==1.24.10\n",
      "  Using cached PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "Collecting PyMuPDFb==1.24.10\n",
      "  Using cached PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "Collecting pyparsing==3.1.4\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (2.9.0.post0)\n",
      "Collecting python-dotenv==1.0.1\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting PyYAML==6.0.2\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 85)) (26.2.0)\n",
      "Collecting regex==2024.9.11\n",
      "  Using cached regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting requests-toolbelt==1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting rsa==4.9\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting sgmllib3k==1.0.0\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 91)) (1.16.0)\n",
      "Collecting sniffio==1.3.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting SQLAlchemy==2.0.35\n",
      "  Using cached SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 94)) (0.6.3)\n",
      "Collecting tenacity==8.5.0\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting tiktoken==0.7.0\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: tornado==6.4.1 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 97)) (6.4.1)\n",
      "Collecting tqdm==4.66.5\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 99)) (5.14.3)\n",
      "Collecting typing-inspect==0.9.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 101)) (4.12.2)\n",
      "Collecting uritemplate==4.1.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting urllib3==2.2.3\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./venv/lib/python3.10/site-packages (from -r requirements.txt (line 104)) (0.2.13)\n",
      "Collecting yarl==1.13.1\n",
      "  Using cached yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'langsmith' candidate (version 0.1.130 at https://files.pythonhosted.org/packages/bf/b0/4c21096c582639a3c949e8e603aa3f53d07104cccdd500153ac3e7135701/langsmith-0.1.130-py3-none-any.whl#sha256=acf27d77e699d84b03045f3f226e78be1dffb3e756aa1a085f9993a45380e8b2 (from https://pypi.org/simple/langsmith/) (requires-python:<4.0,>=3.8.1))\n",
      "Reason for being yanked: Identified some objects that don't serialize well in the optimized form\u001b[0m\u001b[33m\n",
      "\u001b[0mUsing legacy 'setup.py install' for sgmllib3k, since package 'wheel' is not installed.\n",
      "Installing collected packages: sgmllib3k, urllib3, uritemplate, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pyparsing, PyMuPDFb, pydantic_core, pyasn1, protobuf, primp, orjson, numpy, mypy-extensions, multidict, msgpack, marshmallow, jsonpointer, idna, h11, grpcio, greenlet, frozenlist, feedparser, click, charset-normalizer, certifi, cachetools, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, rsa, requests, PyMuPDF, pydantic, pyasn1_modules, proto-plus, jsonpatch, httplib2, httpcore, googleapis-common-protos, faiss-cpu, duckduckgo_search, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic-settings, httpx, grpcio-status, google-auth, dataclasses-json, arxiv, aiohttp, langsmith, google-auth-httplib2, google-api-core, langchain-core, google-api-python-client, langgraph-checkpoint, langchain-text-splitters, google-ai-generativelanguage, langgraph, langchain, google-generativeai, langchain-google-genai, langchain-community\n",
      "  Running setup.py install for sgmllib3k ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10 PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.0 arxiv-2.1.3 async-timeout-4.0.3 attrs-24.2.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.7 duckduckgo_search-6.2.13 faiss-cpu-1.8.0.post1 feedparser-6.0.11 frozenlist-1.4.1 google-ai-generativelanguage-0.6.6 google-api-core-2.20.0 google-api-python-client-2.147.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google-generativeai-0.7.2 googleapis-common-protos-1.65.0 greenlet-3.1.1 grpcio-1.66.2 grpcio-status-1.62.3 h11-0.14.0 httpcore-1.0.6 httplib2-0.22.0 httpx-0.27.2 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-community-0.3.1 langchain-core-0.3.8 langchain-google-genai-2.0.0 langchain-text-splitters-0.3.0 langgraph-0.2.34 langgraph-checkpoint-2.0.0 langsmith-0.1.130 marshmallow-3.22.0 msgpack-1.1.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.7 primp-0.6.3 proto-plus-1.24.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1_modules-0.4.1 pydantic-2.9.2 pydantic-settings-2.5.2 pydantic_core-2.23.4 pyparsing-3.1.4 python-dotenv-1.0.1 regex-2024.9.11 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9 sgmllib3k-1.0.0 sniffio-1.3.1 tenacity-8.5.0 tiktoken-0.7.0 tqdm-4.66.5 typing-inspect-0.9.0 uritemplate-4.1.1 urllib3-2.2.3 yarl-1.13.1\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-04 14:41:44--  https://arxiv.org/pdf/1810.04805.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.131.42, 151.101.3.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/1810.04805 [following]\n",
      "--2024-10-04 14:41:44--  http://arxiv.org/pdf/1810.04805\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 775166 (757K) [application/pdf]\n",
      "Saving to: ‘./data/BERT_arxiv.pdf’\n",
      "\n",
      "./data/BERT_arxiv.p 100%[===================>] 757.00K  3.82MB/s    in 0.2s    \n",
      "\n",
      "2024-10-04 14:41:44 (3.82 MB/s) - ‘./data/BERT_arxiv.pdf’ saved [775166/775166]\n",
      "\n",
      "--2024-10-04 14:41:44--  https://arxiv.org/pdf/2005.11401\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.67.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 885323 (865K) [application/pdf]\n",
      "Saving to: ‘./data/RAG_arxiv.pdf’\n",
      "\n",
      "./data/RAG_arxiv.pd 100%[===================>] 864.57K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-10-04 14:41:44 (6.42 MB/s) - ‘./data/RAG_arxiv.pdf’ saved [885323/885323]\n",
      "\n",
      "--2024-10-04 14:41:45--  https://arxiv.org/pdf/2310.11511\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.195.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1405127 (1.3M) [application/pdf]\n",
      "Saving to: ‘./data/self_rag_arxiv.pdf’\n",
      "\n",
      "./data/self_rag_arx 100%[===================>]   1.34M  8.64MB/s    in 0.2s    \n",
      "\n",
      "2024-10-04 14:41:45 (8.64 MB/s) - ‘./data/self_rag_arxiv.pdf’ saved [1405127/1405127]\n",
      "\n",
      "--2024-10-04 14:41:45--  https://arxiv.org/pdf/2401.15884\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.3.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 643848 (629K) [application/pdf]\n",
      "Saving to: ‘./data/crag_arxiv.pdf’\n",
      "\n",
      "./data/crag_arxiv.p 100%[===================>] 628.76K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-10-04 14:41:45 (6.01 MB/s) - ‘./data/crag_arxiv.pdf’ saved [643848/643848]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "#\n",
    "! wget \"https://arxiv.org/pdf/1810.04805.pdf\" -O ./data/BERT_arxiv.pdf\n",
    "! wget \"https://arxiv.org/pdf/2005.11401\" -O ./data/RAG_arxiv.pdf\n",
    "! wget \"https://arxiv.org/pdf/2310.11511\" -O ./data/self_rag_arxiv.pdf\n",
    "! wget \"https://arxiv.org/pdf/2401.15884\" -O ./data/crag_arxiv.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
    "from typing import List,Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Document Metadata: {'page_label': '1', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(input_files = ['./data/self_rag_arxiv.pdf']).load_data()\n",
    "print(len(documents))\n",
    "print(f\"Document Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the documents into chunks/nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of nodes : 43\n",
      "get the content for node 0 :page_label: 1\n",
      "file_name: self_rag_arxiv.pdf\n",
      "file_path: data/self_rag_arxiv.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 1405127\n",
      "creation_date: 2024-10-04\n",
      "last_modified_date: 2023-10-19\n",
      "\n",
      "Preprint.\n",
      "SELF-RAG: LEARNING TO RETRIEVE , GENERATE ,AND\n",
      "CRITIQUE THROUGH SELF-REFLECTION\n",
      "Akari Asai†, Zeqiu Wu†, Yizhong Wang†§, Avirup Sil‡, Hannaneh Hajishirzi†§\n",
      "†University of Washington§Allen Institute for AI‡IBM Research AI\n",
      "{akari,zeqiuwu,yizhongw,hannaneh }@cs.washington.edu ,avi@us.ibm.com\n",
      "ABSTRACT\n",
      "Despite their remarkable capabilities, large language models (LLMs) often produce\n",
      "responses containing factual inaccuracies due to their sole reliance on the paramet-\n",
      "ric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad\n",
      "hoc approach that augments LMs with retrieval of relevant knowledge, decreases\n",
      "such issues. However, indiscriminately retrieving and incorporating a fixed number\n",
      "of retrieved passages, regardless of whether retrieval is necessary, or passages are\n",
      "relevant, diminishes LM versatility or can lead to unhelpful response generation.\n",
      "We introduce a new framework called Self-Reflective Retrieval-Augmented Gen-\n",
      "eration ( SELF-RAG)that enhances an LM’s quality and factuality through retrieval\n",
      "and self-reflection. Our framework trains a single arbitrary LM that adaptively\n",
      "retrieves passages on-demand, and generates and reflects on retrieved passages\n",
      "and its own generations using special tokens, called reflection tokens. Generating\n",
      "reflection tokens makes the LM controllable during the inference phase, enabling it\n",
      "to tailor its behavior to diverse task requirements. Experiments show that SELF-\n",
      "RAG(7B and 13B parameters) significantly outperforms state-of-the-art LLMs\n",
      "and retrieval-augmented models on a diverse set of tasks. Specifically, SELF-RAG\n",
      "outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA,\n",
      "reasoning and fact verification tasks, and it shows significant gains in improving\n",
      "factuality and citation accuracy for long-form generations relative to these models.1\n",
      "1 I NTRODUCTION\n",
      "State-of-the-art LLMs continue to struggle with factual errors (Mallen et al., 2023; Min et al., 2023)\n",
      "despite their increased model and data scale (Ouyang et al., 2022). Retrieval-Augmented Generation\n",
      "(RAG) methods (Figure 1 left; Lewis et al. 2020; Guu et al. 2020) augment the input of LLMs\n",
      "with relevant retrieved passages, reducing factual errors in knowledge-intensive tasks (Ram et al.,\n",
      "2023; Asai et al., 2023a). However, these methods may hinder the versatility of LLMs or introduce\n",
      "unnecessary or off-topic passages that lead to low-quality generations (Shi et al., 2023) since they\n",
      "retrieve passages indiscriminately regardless of whether the factual grounding is helpful. Moreover,\n",
      "the output is not guaranteed to be consistent with retrieved relevant passages (Gao et al., 2023) since\n",
      "the models are not explicitly trained to leverage and follow facts from provided passages. This\n",
      "work introduces Self-Reflective Retrieval-augmented Generation ( SELF-RAG)to improve an\n",
      "LLM’s generation quality, including its factual accuracy without hurting its versatility, via on-demand\n",
      "retrieval and self-reflection. We train an arbitrary LM in an end-to-end manner to learn to reflect on\n",
      "its own generation process given a task input by generating both task output and intermittent special\n",
      "tokens (i.e., reflection tokens ). Reflection tokens are categorized into retrieval andcritique tokens to\n",
      "indicate the need for retrieval and its generation quality respectively (Figure 1 right). In particular,\n",
      "given an input prompt and preceding generations, SELF-RAGfirst determines if augmenting the\n",
      "continued generation with retrieved passages would be helpful. If so, it outputs a retrieval token that\n",
      "calls a retriever model on demand (Step 1). Subsequently, SELF-RAGconcurrently processes multiple\n",
      "retrieved passages, evaluating their relevance and then generating corresponding task outputs (Step\n",
      "2). It then generates critique tokens to criticize its own output and choose best one (Step 3) in terms\n",
      "of factuality and overall quality. This process differs from conventional RAG (Figure 1 left), which\n",
      "1Our code and trained models are available at https://selfrag.github.io/ .\n",
      "1arXiv:2310.11511v1  [cs.CL]  17 Oct 2023\n"
     ]
    }
   ],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Length of nodes : {len(nodes)}\")\n",
    "print(f\"get the content for node 0 :{nodes[0].get_content(metadata_mode='all')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db_mistral\")\n",
    "chroma_collection = db.get_or_create_collection(\"multidocument-agent\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fx/Downloads/Projects/multi-agent-rag/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:31<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "Settings.chunk_size = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "\n",
    "load_dotenv()\n",
    "# mistral_api_key=  os.environ[\"MISTRAL_API_KEY\"] \n",
    "llm = MistralAI(model=\"mistral-large-latest\",api_key=os.getenv(\"MISTRAL_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 7ccbb8d8-e7c2-4bd8-8b94-3684ad6f67b6\n",
      "Add of existing embedding ID: dbda8faa-81c9-4a27-8524-dd98c9633c9e\n",
      "Add of existing embedding ID: 6e9c8032-2133-4a59-9a49-34a32f09d34a\n",
      "Add of existing embedding ID: 93a60dcd-0bfc-4c2c-ab2b-d659b5065e53\n",
      "Add of existing embedding ID: 4f803f2e-11df-4015-a92a-184ddda23666\n",
      "Add of existing embedding ID: 2a08ab2c-4c54-463f-a5ff-7656008e9ec6\n",
      "Add of existing embedding ID: d25218e9-ca55-4e3f-b076-05e66deeec91\n",
      "Add of existing embedding ID: 3ba2fe0a-6525-4779-aa7d-14958a151376\n",
      "Add of existing embedding ID: dacc0850-27aa-4a5e-827c-908fe6b1ec1c\n",
      "Add of existing embedding ID: b4422c0d-15ef-4d24-942a-87381265674a\n",
      "Add of existing embedding ID: fc9a841f-5241-4e32-9eef-275de9d0eef4\n",
      "Add of existing embedding ID: 964436bd-7ccc-4345-a512-cd5a060dc757\n",
      "Add of existing embedding ID: 4a2fd4cf-ad13-450a-ad34-1d8a0bc46430\n",
      "Add of existing embedding ID: ad79ace7-53c5-4914-a41a-ea02cfd2a875\n",
      "Add of existing embedding ID: e301813a-20da-42cc-9155-18b17805a367\n",
      "Add of existing embedding ID: 4db8b72b-9ef2-4824-8469-d815438ed860\n",
      "Add of existing embedding ID: 14b10a1f-7903-4d2b-bf50-47ce76367407\n",
      "Add of existing embedding ID: 2167f5e7-0bc5-4381-a32f-4453866fac86\n",
      "Add of existing embedding ID: f9f0f78e-e5f8-4615-b2ca-605ea6eb254d\n",
      "Add of existing embedding ID: f20ec931-0d41-4d7d-8e22-03899b8835f5\n",
      "Add of existing embedding ID: ee51d23d-7ed2-4b4a-8037-82814f258be6\n",
      "Add of existing embedding ID: a1810486-e8e1-4708-95b8-37180fc7a5aa\n",
      "Add of existing embedding ID: 13587b87-501b-43f9-b9e7-1a48ff6d8e69\n",
      "Add of existing embedding ID: fbb7d5ff-03a6-40f6-bcfc-d904079ea5fc\n",
      "Add of existing embedding ID: b1dfa3ce-7fd9-42ba-98dc-5db1cf231b9a\n",
      "Add of existing embedding ID: 57dda496-fd57-4e84-a9a9-aa13693ca95c\n",
      "Add of existing embedding ID: b610f2ae-5a7c-4c1d-8ce2-86f34d3bacb7\n",
      "Add of existing embedding ID: 92167f4e-9b84-4680-8672-a006308ccf30\n",
      "Add of existing embedding ID: 27fbc7f6-ff44-46f3-a907-fd8419355ea3\n",
      "Add of existing embedding ID: 90da639c-a030-42a4-a26e-5d43b8231627\n",
      "Add of existing embedding ID: c7dd7f74-d7af-405e-a454-f2bb51c1843e\n",
      "Add of existing embedding ID: b4c6fd85-4614-4993-89eb-6b3677571996\n",
      "Add of existing embedding ID: 04414e7f-b4d8-4a32-afdd-2c7442a0caf1\n",
      "Add of existing embedding ID: 1a191f54-9de5-455e-aae5-1a0b8a8a2071\n",
      "Add of existing embedding ID: c87ca134-dc7c-4e53-b915-fd9a337d613c\n",
      "Add of existing embedding ID: 30969728-e390-4de0-837e-322c430bfb68\n",
      "Add of existing embedding ID: fe72f381-ea72-4869-996e-6185918f1d16\n",
      "Add of existing embedding ID: 24056096-3c68-4ba7-b99b-a81d16f448ff\n",
      "Add of existing embedding ID: bb461e84-e149-4200-aade-567af0683fe9\n",
      "Add of existing embedding ID: fe660ebf-b1b2-49d4-829c-5c0ab98203df\n",
      "Add of existing embedding ID: d074f208-8398-4393-ac58-3a655ca04d65\n",
      "Add of existing embedding ID: b2549d05-f087-47d2-8dac-87ff1f44a0aa\n",
      "Add of existing embedding ID: 70fd28ef-40d0-4a52-9758-70b309cbb374\n",
      "Insert of existing embedding ID: 7ccbb8d8-e7c2-4bd8-8b94-3684ad6f67b6\n",
      "Insert of existing embedding ID: dbda8faa-81c9-4a27-8524-dd98c9633c9e\n",
      "Insert of existing embedding ID: 6e9c8032-2133-4a59-9a49-34a32f09d34a\n",
      "Insert of existing embedding ID: 93a60dcd-0bfc-4c2c-ab2b-d659b5065e53\n",
      "Insert of existing embedding ID: 4f803f2e-11df-4015-a92a-184ddda23666\n",
      "Insert of existing embedding ID: 2a08ab2c-4c54-463f-a5ff-7656008e9ec6\n",
      "Insert of existing embedding ID: d25218e9-ca55-4e3f-b076-05e66deeec91\n",
      "Insert of existing embedding ID: 3ba2fe0a-6525-4779-aa7d-14958a151376\n",
      "Insert of existing embedding ID: dacc0850-27aa-4a5e-827c-908fe6b1ec1c\n",
      "Insert of existing embedding ID: b4422c0d-15ef-4d24-942a-87381265674a\n",
      "Insert of existing embedding ID: fc9a841f-5241-4e32-9eef-275de9d0eef4\n",
      "Insert of existing embedding ID: 964436bd-7ccc-4345-a512-cd5a060dc757\n",
      "Insert of existing embedding ID: 4a2fd4cf-ad13-450a-ad34-1d8a0bc46430\n",
      "Insert of existing embedding ID: ad79ace7-53c5-4914-a41a-ea02cfd2a875\n",
      "Insert of existing embedding ID: e301813a-20da-42cc-9155-18b17805a367\n",
      "Insert of existing embedding ID: 4db8b72b-9ef2-4824-8469-d815438ed860\n",
      "Insert of existing embedding ID: 14b10a1f-7903-4d2b-bf50-47ce76367407\n",
      "Insert of existing embedding ID: 2167f5e7-0bc5-4381-a32f-4453866fac86\n",
      "Insert of existing embedding ID: f9f0f78e-e5f8-4615-b2ca-605ea6eb254d\n",
      "Insert of existing embedding ID: f20ec931-0d41-4d7d-8e22-03899b8835f5\n",
      "Insert of existing embedding ID: ee51d23d-7ed2-4b4a-8037-82814f258be6\n",
      "Insert of existing embedding ID: a1810486-e8e1-4708-95b8-37180fc7a5aa\n",
      "Insert of existing embedding ID: 13587b87-501b-43f9-b9e7-1a48ff6d8e69\n",
      "Insert of existing embedding ID: fbb7d5ff-03a6-40f6-bcfc-d904079ea5fc\n",
      "Insert of existing embedding ID: b1dfa3ce-7fd9-42ba-98dc-5db1cf231b9a\n",
      "Insert of existing embedding ID: 57dda496-fd57-4e84-a9a9-aa13693ca95c\n",
      "Insert of existing embedding ID: b610f2ae-5a7c-4c1d-8ce2-86f34d3bacb7\n",
      "Insert of existing embedding ID: 92167f4e-9b84-4680-8672-a006308ccf30\n",
      "Insert of existing embedding ID: 27fbc7f6-ff44-46f3-a907-fd8419355ea3\n",
      "Insert of existing embedding ID: 90da639c-a030-42a4-a26e-5d43b8231627\n",
      "Insert of existing embedding ID: c7dd7f74-d7af-405e-a454-f2bb51c1843e\n",
      "Insert of existing embedding ID: b4c6fd85-4614-4993-89eb-6b3677571996\n",
      "Insert of existing embedding ID: 04414e7f-b4d8-4a32-afdd-2c7442a0caf1\n",
      "Insert of existing embedding ID: 1a191f54-9de5-455e-aae5-1a0b8a8a2071\n",
      "Insert of existing embedding ID: c87ca134-dc7c-4e53-b915-fd9a337d613c\n",
      "Insert of existing embedding ID: 30969728-e390-4de0-837e-322c430bfb68\n",
      "Insert of existing embedding ID: fe72f381-ea72-4869-996e-6185918f1d16\n",
      "Insert of existing embedding ID: 24056096-3c68-4ba7-b99b-a81d16f448ff\n",
      "Insert of existing embedding ID: bb461e84-e149-4200-aade-567af0683fe9\n",
      "Insert of existing embedding ID: fe660ebf-b1b2-49d4-829c-5c0ab98203df\n",
      "Insert of existing embedding ID: d074f208-8398-4393-ac58-3a655ca04d65\n",
      "Insert of existing embedding ID: b2549d05-f087-47d2-8dac-87ff1f44a0aa\n",
      "Insert of existing embedding ID: 70fd28ef-40d0-4a52-9758-70b309cbb374\n"
     ]
    }
   ],
   "source": [
    "#instantiate Vectorstore\n",
    "from llama_index.core.llms import MockLLM\n",
    "name = \"BERT_arxiv\"\n",
    "vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "#\n",
    "# Define Vectorstore Autoretrieval tool\n",
    "def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "  '''\n",
    "  perform vector search over index on\n",
    "  query(str): query string needs to be embedded\n",
    "  page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                          leave blank if we want to perform a vector search over all pages\n",
    "  '''\n",
    "  page_numbers = page_numbers or []\n",
    "  metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "  #\n",
    "  query_engine = vector_index.as_query_engine(llm=MockLLM(),similarity_top_k =2,\n",
    "                                              filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                    condition=FilterCondition.OR)\n",
    "                                              )\n",
    "  #\n",
    "  response = query_engine.query(query)\n",
    "  return response\n",
    "#\n",
    "#llamiondex FunctionTool wraps any python function we feed it\n",
    "vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                              fn=vector_query)\n",
    "# Prepare Summary Tool\n",
    "summary_index = SummaryIndex(nodes)\n",
    "# summary_query_engine = summary_index.as_query_engine(llm=MockLLM(), embed_model=\"local\")\n",
    "summary_query_engine = summary_index.as_query_engine(llm=MockLLM(), response_mode=\"tree_summarize\",\n",
    "                                                      se_async=True,)\n",
    "summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                    query_engine=summary_query_engine,\n",
    "                                                  description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                              \"DO NOT USE if you have specified questions over the documents.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool_BERT_arxiv with args: {\"query\": \"Summarize the content in page number 2\", \"page_numbers\": [\"2\"]}\n",
      "=== Function Output ===\n",
      "Context information is below.\n",
      "---------------------\n",
      "page_label: 2\n",
      "file_path: data/self_rag_arxiv.pdf\n",
      "\n",
      "Our analysis demonstrates the effectiveness of training and inference with\n",
      "reflection tokens for overall performance improvements as well as test-time model customizations\n",
      "(e.g., balancing the trade-off between citation previsions and completeness).\n",
      "2 R ELATED WORK\n",
      "Retrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\n",
      "space of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\n",
      "improvements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\n",
      "et al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\n",
      "2\n",
      "\n",
      "page_label: 2\n",
      "file_path: data/self_rag_arxiv.pdf\n",
      "\n",
      "Preprint.\n",
      "Step 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \n",
      "US states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\n",
      "Retrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \n",
      "Popular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \n",
      "Prompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\n",
      "LM\n",
      "Prompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \n",
      "Prompt +  \n",
      "11 of 50 state namesRelevant\n",
      "Step 2: Generate segment in parallel \n",
      "come from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\n",
      "US states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \n",
      "Prompt: Write an essay of your best summer vacation\n",
      "Prompt: Write an essay of your best summer vacation\n",
      "No RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \n",
      ">Repeat.…\n",
      "No information in passagesContradictory>Prompt +  \n",
      "Prompt +  \n",
      "Retrieve\n",
      "Figure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\n",
      "to enhance overall generation quality, factuality, and verifiability.\n",
      "consistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\n",
      "(e.g., the bottom figure example does not require factual knowledge) and never second visits the\n",
      "generation quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\n",
      "of whether the output is supported by the passage, leading to easier fact verification.\n",
      "SELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\n",
      "next token prediction from the expanded model vocabulary. We train our generator LM on a diverse\n",
      "collection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\n",
      "by reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\n",
      "inserted offline into the original corpus by a trained critic model. This eliminates the need to host a\n",
      "critic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\n",
      "of input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\n",
      "GPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\n",
      "guide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\n",
      "assess its own predictions after each generated segment as an integral part of the generation output.\n",
      "SELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\n",
      "which are defined by reflection token predictions. In particular, our inference-time algorithm enables\n",
      "us to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\n",
      "models’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\n",
      "search using the weighted linear sum of the reflection token probabilities as segment score.\n",
      "Empirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\n",
      "RAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\n",
      "widely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\n",
      "retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\n",
      "et al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\n",
      "reflection tokens for overall performance improvements as well as test-time model customizations\n",
      "(e.g., balancing the trade-off between citation previsions and completeness).\n",
      "2 R ELATED WORK\n",
      "Retrieval-Augmented Generation.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Summarize the content in page number 2\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"Context information is below.\\n---------------------\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nOur analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\\nspace of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\\nimprovements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\\net al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\\n2\\n\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nPreprint.\\nStep 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \\nUS states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\\nRetrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \\nPopular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \\nPrompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\\nLM\\nPrompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \\nPrompt +  \\n11 of 50 state namesRelevant\\nStep 2: Generate segment in parallel \\ncome from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\\nUS states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \\nPrompt: Write an essay of your best summer vacation\\nPrompt: Write an essay of your best summer vacation\\nNo RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \\n>Repeat.…\\nNo information in passagesContradictory>Prompt +  \\nPrompt +  \\nRetrieve\\nFigure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\\nto enhance overall generation quality, factuality, and verifiability.\\nconsistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\\n(e.g., the bottom figure example does not require factual knowledge) and never second visits the\\ngeneration quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\\nof whether the output is supported by the passage, leading to easier fact verification.\\nSELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\\nnext token prediction from the expanded model vocabulary. We train our generator LM on a diverse\\ncollection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\\nby reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\\ninserted offline into the original corpus by a trained critic model. This eliminates the need to host a\\ncritic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\\nof input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\\nGPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\\nguide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\\nassess its own predictions after each generated segment as an integral part of the generation output.\\nSELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\\nwhich are defined by reflection token predictions. In particular, our inference-time algorithm enables\\nus to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\\nmodels’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\\nsearch using the weighted linear sum of the reflection token probabilities as segment score.\\nEmpirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\\nRAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\\nwidely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\\nretrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\\net al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: Summarize the content in page number 2\\nAnswer: \", sources=[ToolOutput(content=\"Context information is below.\\n---------------------\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nOur analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\\nspace of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\\nimprovements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\\net al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\\n2\\n\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nPreprint.\\nStep 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \\nUS states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\\nRetrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \\nPopular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \\nPrompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\\nLM\\nPrompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \\nPrompt +  \\n11 of 50 state namesRelevant\\nStep 2: Generate segment in parallel \\ncome from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\\nUS states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \\nPrompt: Write an essay of your best summer vacation\\nPrompt: Write an essay of your best summer vacation\\nNo RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \\n>Repeat.…\\nNo information in passagesContradictory>Prompt +  \\nPrompt +  \\nRetrieve\\nFigure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\\nto enhance overall generation quality, factuality, and verifiability.\\nconsistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\\n(e.g., the bottom figure example does not require factual knowledge) and never second visits the\\ngeneration quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\\nof whether the output is supported by the passage, leading to easier fact verification.\\nSELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\\nnext token prediction from the expanded model vocabulary. We train our generator LM on a diverse\\ncollection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\\nby reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\\ninserted offline into the original corpus by a trained critic model. This eliminates the need to host a\\ncritic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\\nof input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\\nGPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\\nguide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\\nassess its own predictions after each generated segment as an integral part of the generation output.\\nSELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\\nwhich are defined by reflection token predictions. In particular, our inference-time algorithm enables\\nus to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\\nmodels’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\\nsearch using the weighted linear sum of the reflection token probabilities as segment score.\\nEmpirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\\nRAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\\nwidely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\\nretrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\\net al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: Summarize the content in page number 2\\nAnswer: \", tool_name='vector_tool_BERT_arxiv', raw_input={'args': (), 'kwargs': {'query': 'Summarize the content in page number 2', 'page_numbers': ['2']}}, raw_output=Response(response=\"Context information is below.\\n---------------------\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nOur analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\\nspace of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\\nimprovements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\\net al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\\n2\\n\\npage_label: 2\\nfile_path: data/self_rag_arxiv.pdf\\n\\nPreprint.\\nStep 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \\nUS states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\\nRetrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \\nPopular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \\nPrompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\\nLM\\nPrompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \\nPrompt +  \\n11 of 50 state namesRelevant\\nStep 2: Generate segment in parallel \\ncome from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\\nUS states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \\nPrompt: Write an essay of your best summer vacation\\nPrompt: Write an essay of your best summer vacation\\nNo RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \\n>Repeat.…\\nNo information in passagesContradictory>Prompt +  \\nPrompt +  \\nRetrieve\\nFigure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\\nto enhance overall generation quality, factuality, and verifiability.\\nconsistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\\n(e.g., the bottom figure example does not require factual knowledge) and never second visits the\\ngeneration quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\\nof whether the output is supported by the passage, leading to easier fact verification.\\nSELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\\nnext token prediction from the expanded model vocabulary. We train our generator LM on a diverse\\ncollection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\\nby reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\\ninserted offline into the original corpus by a trained critic model. This eliminates the need to host a\\ncritic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\\nof input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\\nGPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\\nguide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\\nassess its own predictions after each generated segment as an integral part of the generation output.\\nSELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\\nwhich are defined by reflection token predictions. In particular, our inference-time algorithm enables\\nus to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\\nmodels’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\\nsearch using the weighted linear sum of the reflection token probabilities as segment score.\\nEmpirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\\nRAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\\nwidely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\\nretrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\\net al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: Summarize the content in page number 2\\nAnswer: \", source_nodes=[NodeWithScore(node=TextNode(id_='6e9c8032-2133-4a59-9a49-34a32f09d34a', embedding=None, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cdfde518-0d5b-4d1f-988a-2fe57d0d311b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='1290825ee142097053604deff86edac045142e4216105dc1ba849d56cff603e2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dbda8faa-81c9-4a27-8524-dd98c9633c9e', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='e91f946a495e8f022466597b286015c996705c400737e81b381c5e0eaf6e73f3')}, text='Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\\nspace of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\\nimprovements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\\net al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\\n2', mimetype='text/plain', start_char_idx=4065, end_char_idx=4712, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.45185550738975583), NodeWithScore(node=TextNode(id_='dbda8faa-81c9-4a27-8524-dd98c9633c9e', embedding=None, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cdfde518-0d5b-4d1f-988a-2fe57d0d311b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='1290825ee142097053604deff86edac045142e4216105dc1ba849d56cff603e2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e9c8032-2133-4a59-9a49-34a32f09d34a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a20d4361b3a52d71a93212deb7397ee85ce4ffa77605cc6561d7de0d24386e3f')}, text=\"Preprint.\\nStep 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \\nUS states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\\nRetrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \\nPopular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \\nPrompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\\nLM\\nPrompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \\nPrompt +  \\n11 of 50 state namesRelevant\\nStep 2: Generate segment in parallel \\ncome from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\\nUS states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \\nPrompt: Write an essay of your best summer vacation\\nPrompt: Write an essay of your best summer vacation\\nNo RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \\n>Repeat.…\\nNo information in passagesContradictory>Prompt +  \\nPrompt +  \\nRetrieve\\nFigure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\\nto enhance overall generation quality, factuality, and verifiability.\\nconsistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\\n(e.g., the bottom figure example does not require factual knowledge) and never second visits the\\ngeneration quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\\nof whether the output is supported by the passage, leading to easier fact verification.\\nSELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\\nnext token prediction from the expanded model vocabulary. We train our generator LM on a diverse\\ncollection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\\nby reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\\ninserted offline into the original corpus by a trained critic model. This eliminates the need to host a\\ncritic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\\nof input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\\nGPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\\nguide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\\nassess its own predictions after each generated segment as an integral part of the generation output.\\nSELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\\nwhich are defined by reflection token predictions. In particular, our inference-time algorithm enables\\nus to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\\nmodels’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\\nsearch using the weighted linear sum of the reflection token probabilities as segment score.\\nEmpirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\\nRAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\\nwidely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\\nretrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\\net al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation.\", mimetype='text/plain', start_char_idx=0, end_char_idx=4362, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.41264156534227375)], metadata={'6e9c8032-2133-4a59-9a49-34a32f09d34a': {'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, 'dbda8faa-81c9-4a27-8524-dd98c9633c9e': {'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}}), is_error=False)], source_nodes=[NodeWithScore(node=TextNode(id_='6e9c8032-2133-4a59-9a49-34a32f09d34a', embedding=None, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cdfde518-0d5b-4d1f-988a-2fe57d0d311b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='1290825ee142097053604deff86edac045142e4216105dc1ba849d56cff603e2'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dbda8faa-81c9-4a27-8524-dd98c9633c9e', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='e91f946a495e8f022466597b286015c996705c400737e81b381c5e0eaf6e73f3')}, text='Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation. Retrieval-Augmented Generation (RAG) augments the input\\nspace of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), leading to large\\nimprovements in knowledge-intensive tasks after fine-tuning or used with off-the-shelf LMs (Ram\\net al., 2023). A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number\\n2', mimetype='text/plain', start_char_idx=4065, end_char_idx=4712, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.45185550738975583), NodeWithScore(node=TextNode(id_='dbda8faa-81c9-4a27-8524-dd98c9633c9e', embedding=None, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cdfde518-0d5b-4d1f-988a-2fe57d0d311b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '2', 'file_name': 'self_rag_arxiv.pdf', 'file_path': 'data/self_rag_arxiv.pdf', 'file_type': 'application/pdf', 'file_size': 1405127, 'creation_date': '2024-10-04', 'last_modified_date': '2023-10-19'}, hash='1290825ee142097053604deff86edac045142e4216105dc1ba849d56cff603e2'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6e9c8032-2133-4a59-9a49-34a32f09d34a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a20d4361b3a52d71a93212deb7397ee85ce4ffa77605cc6561d7de0d24386e3f')}, text=\"Preprint.\\nStep 1: Retrieve K documentsCalifornia was named after a ﬁctional island in a Spanish book. Prompt How did US states get their names? \\nUS states got their names from a variety of sources. Eleven states are named after an individual person (e.g, California was named after Christopher Columbus). Some states including Texas and Utah, are named after Native American tribe.\\nRetrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Generation (Self-RAG) \\nPopular names by states. In Texas, Emma is a popular baby name. Of the ﬁfty states, eleven are named after an individual person. \\nPrompt How did US states get their names? + Step 2: Prompt LM with K docs and generateRetriever\\nLM\\nPrompt How did US states get their names? US states got their names from a variety of sources. RetrieveStep 1: Retrieve on demand  \\nPrompt +  \\n11 of 50 state namesRelevant\\nStep 2: Generate segment in parallel \\ncome from persons.SupportedIrrelevantTexas is namedafter a Native American tribe. Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián. California's name has itsRelevantPartially\\nUS states got their names from a variety of sources. 11 of 50 states names are come from persons.    26 states are named after Native Americans, including Utah. \\nPrompt: Write an essay of your best summer vacation\\nPrompt: Write an essay of your best summer vacation\\nNo RetrievalMy best summer vacation is when my family and I embarked on a road trip along …My best… \\n>Repeat.…\\nNo information in passagesContradictory>Prompt +  \\nPrompt +  \\nRetrieve\\nFigure 1: Overview of SELF-RAG.SELF-RAGlearns to retrieve, critique, and generate text passages\\nto enhance overall generation quality, factuality, and verifiability.\\nconsistently retrieves a fixed number of documents for generation regardless of the retrieval necessity\\n(e.g., the bottom figure example does not require factual knowledge) and never second visits the\\ngeneration quality. Moreover, SELF-RAGprovides citations for each segment with its self-assessment\\nof whether the output is supported by the passage, leading to easier fact verification.\\nSELF-RAGtrains an arbitrary LM to generate text with reflection tokens by unifying them as the\\nnext token prediction from the expanded model vocabulary. We train our generator LM on a diverse\\ncollection of text interleaved with reflection tokens and retrieved passages. Reflection tokens, inspired\\nby reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are\\ninserted offline into the original corpus by a trained critic model. This eliminates the need to host a\\ncritic model during training, reducing overhead. The critic model, in part, is supervised on a dataset\\nof input, output, and corresponding reflection tokens collected by prompting a propriety LM (i.e.,\\nGPT-4; OpenAI 2023). While we draw inspiration from studies that use control tokens to start and\\nguide text generation (Lu et al., 2022; Keskar et al., 2019), our trained LM uses critique tokens to\\nassess its own predictions after each generated segment as an integral part of the generation output.\\nSELF-RAGfurther enables a customizable decoding algorithm to satisfy hard or soft constraints,\\nwhich are defined by reflection token predictions. In particular, our inference-time algorithm enables\\nus to (1) flexibly adjust retrieval frequency for different downstream applications and (2) customize\\nmodels’ behaviors to user preferences by leveraging reflection tokens through segment-level beam\\nsearch using the weighted linear sum of the reflection token probabilities as segment score.\\nEmpirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF-\\nRAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and\\nwidely adopted RAG approaches with higher citation accuracy. In particular, SELF-RAGoutperforms\\nretrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois\\net al., 2023) on all tasks. Our analysis demonstrates the effectiveness of training and inference with\\nreflection tokens for overall performance improvements as well as test-time model customizations\\n(e.g., balancing the trade-off between citation previsions and completeness).\\n2 R ELATED WORK\\nRetrieval-Augmented Generation.\", mimetype='text/plain', start_char_idx=0, end_char_idx=4362, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.41264156534227375)], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.predict_and_call([vector_query_tool],\n",
    "                                \"Summarize the content in page number 2\",\n",
    "                                verbose=True)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
